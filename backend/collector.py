"""
MoltLook é‡‡é›†å¼•æ“
ç‹¬ç«‹è¿è¡Œï¼Œè´Ÿè´£ä» Moltbook API é‡‡é›†æ•°æ®
"""
import asyncio
import logging
import time
from datetime import datetime
from typing import Optional, List, Dict, Any

import aiohttp
import aiosqlite

from app.core.config import settings
from app.services.moltbook_api import MoltbookAPI
from app.services.feature_extractor import feature_extractor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class Collector:
    """æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self):
        self.api = MoltbookAPI()
        self.db_path = settings.DB_PATH
        self.running = False
    
    async def init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        async with aiosqlite.connect(self.db_path, timeout=30) as db:
            # å¯ç”¨ WAL æ¨¡å¼
            await db.execute("PRAGMA journal_mode=WAL;")
            await db.execute("PRAGMA synchronous=NORMAL;")
            await db.execute("PRAGMA busy_timeout = 5000;")
            await db.commit()
            logger.info("Database initialized")
    
    async def get_collection_state(self, db: aiosqlite.Connection) -> Dict[str, Any]:
        """è·å–é‡‡é›†çŠ¶æ€"""
        cursor = await db.execute(
            "SELECT last_seen_id, last_fetch_time, total_posts, total_posts_count FROM collection_state WHERE id = 1"
        )
        row = await cursor.fetchone()
        if row:
            return {
                "last_seen_id": row[0],
                "last_fetch_time": row[1],
                "total_posts": row[2],
                "total_posts_count": row[3] or 0
            }
        return {"last_seen_id": None, "last_fetch_time": 0, "total_posts": 0, "total_posts_count": 0}
    
    async def update_collection_state(
        self, 
        db: aiosqlite.Connection, 
        last_seen_id: Optional[str] = None,
        total_posts: int = None
    ):
        """æ›´æ–°é‡‡é›†çŠ¶æ€"""
        if last_seen_id:
            await db.execute(
                "UPDATE collection_state SET last_seen_id = ?, last_fetch_time = ? WHERE id = 1",
                (last_seen_id, int(time.time()))
            )
        if total_posts is not None:
            await db.execute(
                "UPDATE collection_state SET total_posts = ? WHERE id = 1",
                (total_posts,)
            )
        await db.commit()
    
    async def save_post(self, db: aiosqlite.Connection, post_data: dict) -> bool:
        """
        ä¿å­˜å¸–å­åˆ°æ•°æ®åº“
        
        Returns:
            bool: æ˜¯å¦ä¸ºæ–°å¸–å­
        """
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        cursor = await db.execute(
            "SELECT id FROM posts WHERE id = ?",
            (post_data["id"],)
        )
        if await cursor.fetchone():
            logger.debug(f"Post {post_data['id'][:8]}... already exists, skipping")
            return False
        
        logger.debug(f"Saving new post {post_data['id'][:8]}..., created_at={post_data['created_at']}")
        
        # ç¡®ä¿æœ‰ URL å’Œæ ‡é¢˜
        url = post_data.get("url")
        if not url or "pages not found" in url or "moltbook.com/posts/" in url:
            # ä¿®æ­£ URL æ ¼å¼ï¼šMoltbook å®˜æ–¹å¸–å­çš„æ­£ç¡®è·¯å¾„é€šå¸¸æ˜¯ /post/{id} è€Œä¸æ˜¯ /posts/{id}
            url = f"https://www.moltbook.com/post/{post_data['id']}"
            
        title = post_data.get("title")
        if not title:
            # å¦‚æœæ²¡æ ‡é¢˜ï¼Œå–å†…å®¹å‰ 30 ä¸ªå­—ç¬¦
            content = post_data.get("content", "")
            title = (content[:30] + "...") if len(content) > 30 else content
            if not title:
                title = "æŸ¥çœ‹è¯¦æƒ…"

        # æ’å…¥å¸–å­
        await db.execute(
            """
            INSERT INTO posts (
                id, author_id, content, content_length, parent_id, submolt,
                created_at, fetched_at, conspiracy_score, sentiment,
                llm_analyzed, intent, risk_level, summary, url, title
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (
                post_data["id"],
                post_data["author_id"],
                post_data["content"],
                post_data["content_length"],
                post_data.get("parent_id"),
                post_data["submolt"],
                post_data["created_at"],
                post_data["fetched_at"],
                post_data["conspiracy_score"],
                post_data["sentiment"],
                post_data["llm_analyzed"],
                post_data["intent"],
                post_data["risk_level"],
                post_data["summary"],
                url,
                title
            )
        )
        
        # å¦‚æœé˜´è°‹æŒ‡æ•° >= 2ï¼ŒåŠ å…¥ LLM åˆ†æé˜Ÿåˆ—
        if post_data["conspiracy_score"] >= 2:
            await db.execute(
                """
                INSERT OR IGNORE INTO llm_queue (post_id, content_snippet, priority, added_at)
                VALUES (?, ?, ?, ?)
                """,
                (
                    post_data["id"],
                    post_data["content"][:300],
                    post_data["conspiracy_score"],
                    int(time.time())
                )
            )
        
        # æ›´æ–°æˆ–åˆ›å»º Agent
        await db.execute(
            """
            INSERT INTO agents (id, name, first_seen, last_active, post_count)
            VALUES (?, ?, ?, ?, 1)
            ON CONFLICT(id) DO UPDATE SET
                name = CASE 
                    WHEN name IS NULL OR name = id OR name = 'unknown' THEN excluded.name 
                    ELSE name 
                END,
                last_active = excluded.last_active,
                post_count = post_count + 1
            """,
            (
                post_data["author_id"],
                post_data.get("author_name") or post_data["author_id"],
                post_data["created_at"],
                post_data["created_at"]
            )
        )
        
        # æ›´æ–° Agent çš„é£é™©ç­‰çº§å’Œå¹³å‡é˜´è°‹æŒ‡æ•°
        await self.update_agent_risk_level(db, post_data["author_id"])
        
        logger.debug(f"Successfully saved post {post_data['id'][:8]}...")
        return True
    
    async def save_interaction(
        self, 
        db: aiosqlite.Connection, 
        source_id: str, 
        target_id: str, 
        post_id: str,
        created_at: int
    ):
        """ä¿å­˜äº’åŠ¨å…³ç³»"""
        try:
            await db.execute(
                """
                INSERT OR IGNORE INTO interactions (source_id, target_id, post_id, created_at)
                VALUES (?, ?, ?, ?)
                """,
                (source_id, target_id, post_id, created_at)
            )
            
            # æ›´æ–° Agent çš„äº’åŠ¨è®¡æ•°
            await db.execute(
                "UPDATE agents SET reply_count = reply_count + 1 WHERE id = ?",
                (source_id,)
            )
            await db.execute(
                "UPDATE agents SET be_replied_count = be_replied_count + 1 WHERE id = ?",
                (target_id,)
            )
            
        except Exception as e:
            logger.error(f"Error saving interaction: {e}")

    async def cleanup_old_posts(self, db: aiosqlite.Connection):
        """
        æ¸…ç†æ—§å¸–å­ï¼Œè§„åˆ™ï¼š
        1. æ°¸è¿œä¿ç•™ risk_level ä¸º 'high' æˆ– 'critical' çš„å¸–å­
        2. å¯¹äº 'low' æˆ– 'medium' çš„å¸–å­ï¼Œä»…ä¿ç•™æœ€æ–°çš„ 20000 æ¡
        """
        try:
            # è·å–éœ€è¦æ¸…ç†çš„é£é™©ç­‰çº§æ€»æ•°
            cursor = await db.execute(
                "SELECT COUNT(*) FROM posts WHERE risk_level IN ('low', 'medium') OR risk_level IS NULL"
            )
            low_risk_count = (await cursor.fetchone())[0]
            
            if low_risk_count > 20000:
                # åˆ é™¤è¶…è¿‡ 20000 æ¡ä»¥å¤–çš„ä½/ä¸­é£é™©æ—§å¸–å­
                await db.execute(
                    """
                    DELETE FROM posts
                    WHERE id IN (
                        SELECT id FROM posts
                        WHERE risk_level IN ('low', 'medium') OR risk_level IS NULL
                        ORDER BY created_at DESC
                        LIMIT -1 OFFSET 20000
                    )
                    """
                )
                deleted_count = low_risk_count - 20000
                logger.info(f"Cleaned up {deleted_count} low/medium risk posts, keeping latest 20000")
                
                # æ›´æ–°å†å²æ€»å¸–å­æ•°ï¼ˆç»Ÿè®¡ç”¨ï¼‰
                await db.execute(
                    "UPDATE collection_state SET total_posts_count = total_posts_count + ? WHERE id = 1",
                    (deleted_count,)
                )
                await db.commit()
        except Exception as e:
            logger.error(f"Error cleaning old posts: {e}")
    
    async def update_agent_risk_level(self, db: aiosqlite.Connection, agent_id: str):
        """
        æ›´æ–° Agent çš„é£é™©ç­‰çº§å’Œå¹³å‡é˜´è°‹æŒ‡æ•°
        
        æ ¹æ®è¯¥ Agent æœ€è¿‘ 7 å¤©çš„å¸–å­è®¡ç®—å¹³å‡é˜´è°‹æŒ‡æ•°å’Œé£é™©ç­‰çº§
        """
        try:
            # è·å–æœ€è¿‘ 7 å¤©çš„å¸–å­ç»Ÿè®¡
            seven_days_ago = int(time.time()) - (7 * 24 * 60 * 60)
            
            cursor = await db.execute(
                """
                SELECT 
                    AVG(conspiracy_score) as avg_score,
                    COUNT(*) as post_count,
                    COUNT(CASE WHEN risk_level = 'high' THEN 1 END) as high_count,
                    COUNT(CASE WHEN risk_level = 'critical' THEN 1 END) as critical_count
                FROM posts 
                WHERE author_id = ? AND created_at > ?
                """,
                (agent_id, seven_days_ago)
            )
            row = await cursor.fetchone()
            
            if not row or row[1] == 0:
                # æ²¡æœ‰æœ€è¿‘å¸–å­ï¼Œä¿æŒåŸæ ·
                return
            
            avg_score = row[0] or 0
            post_count = row[1]
            high_count = row[2] or 0
            critical_count = row[3] or 0
            
            # è®¡ç®—é£é™©ç­‰çº§
            risk_level = 'low'
            
            # ä¼˜å…ˆä½¿ç”¨å¸–å­é£é™©ç­‰çº§
            if critical_count > 0:
                risk_level = 'critical'
            elif high_count > 0:
                # å¦‚æœæœ‰é«˜é£é™©å¸–å­ï¼Œæ ¹æ®æ¯”ä¾‹åˆ¤æ–­
                if high_count >= post_count * 0.5:
                    risk_level = 'critical'
                elif high_count >= post_count * 0.3:
                    risk_level = 'high'
                else:
                    risk_level = 'medium'
            else:
                # æ²¡æœ‰é«˜é£é™©å¸–å­ï¼Œæ ¹æ®å¹³å‡é˜´è°‹æŒ‡æ•°åˆ¤æ–­
                if avg_score >= 7:
                    risk_level = 'critical'
                elif avg_score >= 4:
                    risk_level = 'high'
                elif avg_score >= 2:
                    risk_level = 'medium'
                else:
                    risk_level = 'low'
            
            # æ›´æ–° Agent è¡¨
            await db.execute(
                """
                UPDATE agents 
                SET risk_level = ?, avg_conspiracy_7d = ?
                WHERE id = ?
                """,
                (risk_level, round(avg_score, 2), agent_id)
            )
            
            logger.debug(f"Updated agent {agent_id}: risk={risk_level}, avg_score={avg_score:.2f}")
            
        except Exception as e:
            logger.error(f"Error updating agent risk level: {e}")
    
    async def process_posts(self, posts: List[dict]) -> int:
        """
        å¤„ç†å¸–å­åˆ—è¡¨
        
        Returns:
            int: æ–°å¸–å­æ•°é‡
        """
        new_count = 0
        
        async with aiosqlite.connect(self.db_path, timeout=30) as db:
            await db.execute("PRAGMA journal_mode=WAL;")
            await db.execute("PRAGMA busy_timeout = 5000;")
            
            for post in posts:
                try:
                    # æå–ç‰¹å¾
                    features = feature_extractor.extract_features(post)
                    
                    # ä¿å­˜å¸–å­
                    is_new = await self.save_post(db, features)
                    
                    if is_new:
                        new_count += 1
                        
                        # å¦‚æœæ˜¯å›å¤ï¼Œä¿å­˜äº’åŠ¨å…³ç³»
                        if features.get("parent_id"):
                            target_author_id = features.get("parent_author_id")
                            
                            if not target_author_id:
                                # å¦‚æœç‰¹å¾æå–æ²¡æ‹¿åˆ°ï¼Œå†æŸ¥æ•°æ®åº“
                                cursor = await db.execute(
                                    "SELECT author_id FROM posts WHERE id = ?",
                                    (features["parent_id"],)
                                )
                                parent_row = await cursor.fetchone()
                                if parent_row:
                                    target_author_id = parent_row[0]
                            
                            if target_author_id:
                                await self.save_interaction(
                                    db,
                                    features["author_id"],
                                    target_author_id,
                                    features["id"],
                                    features["created_at"]
                                )
                            else:
                                # ä»ç„¶æ²¡æ‰¾åˆ°ï¼Œå¯èƒ½æ˜¯è·¨åˆ†åŒºçš„å›å¤æˆ–æ—§å¸–å­
                                logger.debug(f"Parent author not found for post {features['id']}")
                    
                except Exception as e:
                    logger.error(f"Error processing post {post.get('id')}: {e}")
                    continue
            
            if new_count > 0:
                await self.cleanup_old_posts(db)
            
            # æ˜¾å¼æäº¤æ‰€æœ‰æ›´æ”¹
            await db.commit()
        
        return new_count
    
    async def collection_task(self):
        """é‡‡é›†ä»»åŠ¡ - 60ç§’å¾ªç¯"""
        logger.info("Starting collection task...")
        
        retry_count = 0
        max_retries = 3
        
        while self.running:
            try:
                # è·å–é‡‡é›†çŠ¶æ€
                async with aiosqlite.connect(self.db_path, timeout=30) as db:
                    # å†æ¬¡ç¡®ä¿ WAL æ¨¡å¼ï¼Œé˜²æ­¢ç”±äºå…¶ä»–è¿›ç¨‹å¯¼è‡´çš„é”å®š
                    await db.execute("PRAGMA journal_mode=WAL;")
                    await db.execute("PRAGMA busy_timeout = 5000;")
                    state = await self.get_collection_state(db)
                
                # è·å–å¸–å­ï¼ˆä¸ä½¿ç”¨ after å‚æ•°ï¼Œå› ä¸º API çš„ after å‚æ•°ä¸å¯é ï¼‰
                posts = await self.api.get_posts(
                    sort="new",
                    limit=settings.BATCH_SIZE
                )
                
                if posts:
                    logger.info(f"Fetched {len(posts)} posts")
                    
                    # å¤„ç†å¸–å­ï¼ˆsave_post æ–¹æ³•ä¼šè‡ªåŠ¨è¿‡æ»¤å·²å­˜åœ¨çš„å¸–å­ï¼‰
                    new_count = await self.process_posts(posts)
                    logger.info(f"Saved {new_count} new posts")
                    
                    # æ›´æ–°é‡‡é›†çŠ¶æ€
                    last_post_id = posts[-1].get("id")
                    async with aiosqlite.connect(self.db_path, timeout=30) as db:
                        await db.execute("PRAGMA journal_mode=WAL;")
                        await db.execute("PRAGMA busy_timeout = 5000;")
                        await self.update_collection_state(
                            db, 
                            last_seen_id=last_post_id,
                            total_posts=state["total_posts"] + new_count
                        )
                    retry_count = 0 # æˆåŠŸåé‡ç½®é‡è¯•è®¡æ•°
                else:
                    logger.debug("No new posts")
                    # å¦‚æœè¿ç»­å¤šæ¬¡æ²¡æœ‰æ–°å¸–å­ï¼Œä¸” last_seen_id å­˜åœ¨ï¼Œå°è¯•ç¨å¾®å›é€€ä¸€ç‚¹æ¸¸æ ‡ï¼ˆå¯é€‰é€»è¾‘ï¼‰
                    # æš‚æ—¶ä¿æŒç°çŠ¶ï¼Œä»…æ‰“å°æ—¥å¿—
                
            except Exception as e:
                retry_count += 1
                logger.error(f"Collection error (Retry {retry_count}/{max_retries}): {e}")
                
                # å¦‚æœæ˜¯ç½‘ç»œæˆ– API é”™è¯¯ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´
                if retry_count >= max_retries:
                    logger.warning("Max retries reached, cooling down for 5 minutes...")
                    await asyncio.sleep(300) 
                    retry_count = 0
                else:
                    await asyncio.sleep(10 * retry_count) # æŒ‡æ•°é€€é¿
            
            # ç­‰å¾…è®¾å®šçš„é—´éš”
            await asyncio.sleep(settings.FETCH_INTERVAL)
    
    async def status_check_task(self):
        """çŠ¶æ€æ£€æŸ¥ä»»åŠ¡ - 4å°æ—¶å¾ªç¯"""
        logger.info("Starting status check task...")
        
        while self.running:
            try:
                status = await self.api.get_agent_status()
                
                if status:
                    agent_status = status.get("status", "unknown")
                    logger.info(f"Agent status: {agent_status}")
                    
                    if agent_status == "claimed":
                        logger.info("âœ… Agent is claimed and active")
                    else:
                        logger.warning(f"â³ Agent status: {agent_status}")
                else:
                    logger.error("Failed to get agent status")
                    
            except Exception as e:
                logger.error(f"Status check error: {e}")
            
            # ç­‰å¾… 4 å°æ—¶
            await asyncio.sleep(settings.STATUS_CHECK_INTERVAL)
    
    async def engagement_task(self):
        """å‘å¸–ä»»åŠ¡ - 4.5å°æ—¶å¾ªç¯"""
        logger.info("Starting engagement task...")
        
        # é¦–æ¬¡å»¶è¿Ÿ 30 åˆ†é’Ÿ
        await asyncio.sleep(1800)
        
        while self.running:
            try:
                # ç”Ÿæˆè§‚å¯ŸæŠ¥å‘Š
                content = await self.generate_observation_post()
                
                if content:
                    result = await self.api.create_post(
                        content=content,
                        submolt="general"
                    )
                    
                    if result:
                        logger.info("Posted observation report")
                    else:
                        logger.warning("Failed to post observation report")
                
            except Exception as e:
                logger.error(f"Engagement error: {e}")
            
            # ç­‰å¾… 4.5 å°æ—¶
            await asyncio.sleep(settings.POST_INTERVAL)
    
    async def generate_observation_post(self) -> Optional[str]:
        """ç”Ÿæˆè§‚å¯ŸæŠ¥å‘Šå¸–å­"""
        try:
            async with aiosqlite.connect(self.db_path, timeout=30) as db:
                await db.execute("PRAGMA busy_timeout = 5000;")
                # è·å–æœ€è¿‘ç»Ÿè®¡
                cursor = await db.execute(
                    "SELECT COUNT(*) FROM posts WHERE created_at > strftime('%s', 'now', '-1 hour')"
                )
                posts_last_hour = (await cursor.fetchone())[0]
                
                cursor = await db.execute(
                    "SELECT COUNT(DISTINCT author_id) FROM posts WHERE created_at > strftime('%s', 'now', '-1 day')"
                )
                active_agents = (await cursor.fetchone())[0]
                
                cursor = await db.execute(
                    "SELECT AVG(conspiracy_score) FROM posts WHERE created_at > strftime('%s', 'now', '-1 day')"
                )
                avg_conspiracy = (await cursor.fetchone())[0] or 0
                
                content = f"""ğŸ” MoltLook Observation Report

ğŸ“Š Last Hour: {posts_last_hour} posts
ğŸ‘¥ Active Agents (24h): {active_agents}
âš ï¸ Avg Conspiracy Score: {avg_conspiracy:.2f}/10

Monitoring the network... ğŸ¦"""
                
                return content
                
        except Exception as e:
            logger.error(f"Error generating observation post: {e}")
            return None
    
    async def run(self):
        """è¿è¡Œé‡‡é›†å™¨"""
        logger.info("=" * 60)
        logger.info("MoltLook Collector Starting...")
        logger.info(f"Agent: {settings.AGENT_NAME}")
        logger.info(f"Database: {self.db_path}")
        logger.info("=" * 60)
        
        # åˆå§‹åŒ–æ•°æ®åº“
        await self.init_db()
        
        self.running = True
        
        # å¯åŠ¨ä¸‰ä¸ªä»»åŠ¡
        await asyncio.gather(
            self.collection_task(),
            self.status_check_task(),
            self.engagement_task()
        )
    
    def stop(self):
        """åœæ­¢é‡‡é›†å™¨"""
        logger.info("Stopping collector...")
        self.running = False


async def main():
    """ä¸»å‡½æ•°"""
    collector = Collector()
    
    try:
        await collector.run()
    except KeyboardInterrupt:
        logger.info("Received keyboard interrupt")
        collector.stop()
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        collector.stop()


if __name__ == "__main__":
    asyncio.run(main())
